# ğŸ¤– AutoGen Local Workflow Suite

[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)

**Zero-cost multi-agent AI workflow suite.** Runs 100% locally on your GPU with Ollama. No cloud APIs required.

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| **Multi-Agent Crew** | Analyst, Researcher, Coder, Reviewer, Executor working together |
| **Code Review** | Security, Performance, Style, Architecture analysis |
| **Research Pipeline** | Query expansion, fact-checking, synthesis |
| **CI/CD Automation** | Lint, test, build, deploy with auto-fix |
| **Task Orchestrator** | Parallel execution with priorities and dependencies |
| **BFT Consensus** | Byzantine fault tolerant agent voting |
| **Genetic Evolution** | Evolve optimal prompts over generations |
| **Swarm Intelligence** | Ant colony optimization for solution search |
| **Self-Healing** | Auto-recovery from failures |
| **Persistent Memory** | SQLite + embeddings semantic search |
| **Distributed Comms** | Redis pub/sub, ZeroMQ mesh networking |
| **Observability** | Full tracing with metrics |
| **REPL Playground** | Interactive agent testing |
| **Web Dashboard** | Real-time monitoring UI |

## ğŸš€ Quick Start

```bash
# 1. Clone
git clone https://github.com/DamianWnorowski/autogen-local.git
cd autogen-local

# 2. Setup (installs Ollama + models + dependencies)
chmod +x setup.sh && ./setup.sh

# 3. Activate and run
source venv/bin/activate
python main.py status
```

## ğŸ“‹ Commands

```bash
python main.py status                    # Check system status
python main.py crew "Build a REST API"   # Run multi-agent crew
python main.py review ./src              # Code review
python main.py research "BFT consensus"  # Deep research
python main.py ci ./project              # Run CI/CD pipeline
python main.py orchestrate               # Parallel task demo
python main.py chat                      # Interactive chat
```

## ğŸ Python API

```python
from autogen_local import quick_crew, quick_review, quick_research, chat

# Multi-agent collaboration
result = quick_crew("Design a microservice architecture")

# Code review
findings = quick_review("./src")

# Research
report = quick_research("Byzantine fault tolerance")

# Simple chat
response = chat("Explain transformers")
```

## ğŸ“ Project Structure

```
autogen_local/
â”œâ”€â”€ config.py              # Global settings
â”œâ”€â”€ local_bridge.py        # Ollama LLM wrapper
â”œâ”€â”€ main.py                # CLI launcher
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ base.py            # Agent factory
â”‚   â”œâ”€â”€ crew.py            # Multi-agent crew
â”‚   â”œâ”€â”€ swarm.py           # Swarm intelligence
â”‚   â”œâ”€â”€ genetic.py         # Genetic prompt evolution
â”‚   â”œâ”€â”€ bft_consensus.py   # Byzantine consensus
â”‚   â”œâ”€â”€ decomposer.py      # Task decomposition
â”‚   â””â”€â”€ self_healing.py    # Self-healing system
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ code_review.py     # Code review pipeline
â”‚   â”œâ”€â”€ research.py        # Research pipeline
â”‚   â”œâ”€â”€ cicd.py            # CI/CD automation
â”‚   â””â”€â”€ orchestrator.py    # Task orchestration
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ persistent.py      # SQLite + embeddings
â”‚   â””â”€â”€ context.py         # Context management
â”œâ”€â”€ comms/
â”‚   â”œâ”€â”€ redis_bus.py       # Redis pub/sub
â”‚   â””â”€â”€ zmq_mesh.py        # ZeroMQ mesh
â”œâ”€â”€ observability/
â”‚   â””â”€â”€ tracing.py         # Distributed tracing
â””â”€â”€ tools/
    â”œâ”€â”€ playground.py      # Interactive REPL
    â”œâ”€â”€ dashboard.py       # Web dashboard
    â””â”€â”€ sandbox.py         # Code execution sandbox
```

## ğŸ³ Docker

```bash
# GPU-accelerated stack
docker compose up -d

# Run commands
docker compose exec autogen python main.py crew "task"
```

## ğŸ’° Cost

**$0.00/forever** â€” Everything runs locally on your GPU.

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.
